---

description: "Guidelines and guardâ€‘rails for developing OpinionFlow â€“ a realâ€‘time, multiâ€‘store reviewâ€‘analysis agent.  Applies to all source code, docs, and notebook files in this repo."
globs:

* "\*\*/\*.py"
* "\*\*/\*.md"
* "Dockerfile"
* "docker-compose.yml"
* "\*.env.example"
* "data/aspects.yaml"
  alwaysApply: true

---

# ğŸ“¦ Project Context

_Project_: **OpinionFlow** â€“ realâ€‘time productâ€‘review intelligence powered by Brightâ€¯Data MCP, FastAPI, Streamlit, PGVector, LangChain RAG.
_Goal_: Users enter a product â†’ agent scrapes Amazon/Walmart/Target reviews live â†’ AI summarises sentiment, pros/cons, aspects â†’ UI displays insights & citations.
_Scope (MVP)_: Instant Answer â–¸ Overall Sentiment â–¸ Pros/Cons â–¸ Store Tabs â–¸ Aspect Miniâ€‘Charts â–¸ Source Explorer.

# ğŸ› ï¸ Build Roadâ€‘map (for Cursor)

1. **Scaffold** repo with folders: `backend/`, `frontend/`, `data/`, `tests/`, `docker/`.
2. **Backend skeleton**: FastAPI app, `/analyze` POST accepting `{product: str}`.
3. **Bright Data client** (`backend/brightdata.py`):
   â€¢ `discover_urls(product)` â€“ SERP API â†’ list\[str]
   â€¢ `scrape_reviews(url)` â€“ Webâ€¯Unlocker + Playwright; must click â€œnext pageâ€ once.
4. **Extraction** (`backend/extractors/*.py`) â€“ siteâ€‘specific HTML â†’ `Review` dataclass.
5. **DB setup** (`models.py`, PGVector). Create tables: `products`, `reviews`.
6. **Embedding pipeline** (`backend/embedding.py`) â€“ MiniLM via SentenceTransformers.
7. **Aspect analysis** (`backend/aspects.py`) â€“ YAML map + Gemini prompt.
8. **RAG QA** (`backend/qa.py`) â€“ LangChain RetrievalQA (LLM = Llamaâ€‘3 or GPTâ€‘4).
9. **API aggregation** (`backend/analysis.py`) â€“ orchestrates steps 3â€“8.
10. **Streamlit UI** (`frontend/app.py`): sidebar input, store tabs, answer, charts, snippets.
11. **Testing**: pytest for parser, embedding, API; manual e2e run on sample products.

# ğŸ—ï¸ Architecture Principles

- **Single responsibility**: scraper, extractor, embedding, analysis in separate modules.
- **Async first**: use `async def` for I/O (scraping, DB) to maximise concurrency.
- **Config driven**: env vars (`BRIGHT_DATA_TOKEN`, `DATABASE_URL`, etc.); no magic literals.
- **Graceful degradation**: if a store fails, still return aggregated results; UI shows warning.
- **Citations required**: every AI answer must include at least 2 source review IDs.

# ğŸ Python & Style

- Python **3.11**.
- Black + Ruff for formatting/lint (`ruff check . && ruff format .`).
- Typeâ€‘annotate all functions; run `mypy --strict` (allow stubs for external libs).
- Use `pydantic.BaseModel` for request/response schemas.
- No synchronous `requests` in async code â€“ use `httpx.AsyncClient` or Playwrightâ€™s async API.

# ğŸ•¸ï¸ Brightâ€¯Data Usage

- Zone IDs & tokens only via env vars.
- `discover_urls` MUST call Brightâ€¯Data SERP or MCP search (fulfils _Discover_).
- `scrape_reviews` MUST:
  â€¢ load page through Webâ€¯Unlocker (_Access_)
  â€¢ scroll + click once (_Interact_)
  â€¢ extract structured JSON (_Extract_).
- Limit to 100 reviews per store per run; respect site T\&C; pause â‰¥1â€¯s between page clicks.

# ğŸ—„ï¸ Database & Vector Store

- Postgres schema:

  ```sql
  CREATE TABLE products(id serial primary key, name text, last_scraped timestamp);
  CREATE TABLE reviews(id bigserial primary key, product_id int references products,
                       source text, rating real, text text, embed vector(384));
  CREATE INDEX ON reviews USING ivfflat(embed vector_cosine_ops) WITH (lists = 100);
  ```

- Use `sqlalchemy.ext.asyncio` `AsyncSession`.

# ğŸ¤– LLM / RAG Rules

- Retriever: PGVector, `k<=6`, similarity >Â 0.4.
- Prompt template stored in `data/prompts/answer.md`.
- Output parser enforces keys: `overall`, `pros`, `cons`.
- Aspect YAML: `data/aspects.yaml`; update only via PR.

# ğŸ“ Commit & PR

- Conventional commits.
- All new modules require docstring header with purpose.
- PR requires CI: lint + test + build.

# âš ï¸ Antiâ€‘patterns

- No hardâ€‘coded XPath/CSS selectors in multiple files â€“ centralise per extractor.
- Donâ€™t store entire HTML in DB â€“ only structured review JSON.
- Avoid heavy synchronous loops inside FastAPI request handler â€“ offload to asyncio tasks if >5â€¯s.

@README.md
@Dockerfile
@backend/main.py
