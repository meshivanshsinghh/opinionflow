---

description: "Guidelines and guard‑rails for developing OpinionFlow – a real‑time, multi‑store review‑analysis agent.  Applies to all source code, docs, and notebook files in this repo."
globs:

* "\*\*/\*.py"
* "\*\*/\*.md"
* "Dockerfile"
* "docker-compose.yml"
* "\*.env.example"
* "data/aspects.yaml"
  alwaysApply: true

---

# 📦 Project Context

_Project_: **OpinionFlow** – real‑time product‑review intelligence powered by Bright Data MCP, FastAPI, Streamlit, PGVector, LangChain RAG.
_Goal_: Users enter a product → agent scrapes Amazon/Walmart/Target reviews live → AI summarises sentiment, pros/cons, aspects → UI displays insights & citations.
_Scope (MVP)_: Instant Answer ▸ Overall Sentiment ▸ Pros/Cons ▸ Store Tabs ▸ Aspect Mini‑Charts ▸ Source Explorer.

# 🛠️ Build Road‑map (for Cursor)

1. **Scaffold** repo with folders: `backend/`, `frontend/`, `data/`, `tests/`, `docker/`.
2. **Backend skeleton**: FastAPI app, `/analyze` POST accepting `{product: str}`.
3. **Bright Data client** (`backend/brightdata.py`):
   • `discover_urls(product)` – SERP API → list\[str]
   • `scrape_reviews(url)` – Web Unlocker + Playwright; must click “next page” once.
4. **Extraction** (`backend/extractors/*.py`) – site‑specific HTML → `Review` dataclass.
5. **DB setup** (`models.py`, PGVector). Create tables: `products`, `reviews`.
6. **Embedding pipeline** (`backend/embedding.py`) – MiniLM via SentenceTransformers.
7. **Aspect analysis** (`backend/aspects.py`) – YAML map + Gemini prompt.
8. **RAG QA** (`backend/qa.py`) – LangChain RetrievalQA (LLM = Llama‑3 or GPT‑4).
9. **API aggregation** (`backend/analysis.py`) – orchestrates steps 3–8.
10. **Streamlit UI** (`frontend/app.py`): sidebar input, store tabs, answer, charts, snippets.
11. **Testing**: pytest for parser, embedding, API; manual e2e run on sample products.

# 🏗️ Architecture Principles

- **Single responsibility**: scraper, extractor, embedding, analysis in separate modules.
- **Async first**: use `async def` for I/O (scraping, DB) to maximise concurrency.
- **Config driven**: env vars (`BRIGHT_DATA_TOKEN`, `DATABASE_URL`, etc.); no magic literals.
- **Graceful degradation**: if a store fails, still return aggregated results; UI shows warning.
- **Citations required**: every AI answer must include at least 2 source review IDs.

# 🐍 Python & Style

- Python **3.11**.
- Black + Ruff for formatting/lint (`ruff check . && ruff format .`).
- Type‑annotate all functions; run `mypy --strict` (allow stubs for external libs).
- Use `pydantic.BaseModel` for request/response schemas.
- No synchronous `requests` in async code – use `httpx.AsyncClient` or Playwright’s async API.

# 🕸️ Bright Data Usage

- Zone IDs & tokens only via env vars.
- `discover_urls` MUST call Bright Data SERP or MCP search (fulfils _Discover_).
- `scrape_reviews` MUST:
  • load page through Web Unlocker (_Access_)
  • scroll + click once (_Interact_)
  • extract structured JSON (_Extract_).
- Limit to 100 reviews per store per run; respect site T\&C; pause ≥1 s between page clicks.

# 🗄️ Database & Vector Store

- Postgres schema:

  ```sql
  CREATE TABLE products(id serial primary key, name text, last_scraped timestamp);
  CREATE TABLE reviews(id bigserial primary key, product_id int references products,
                       source text, rating real, text text, embed vector(384));
  CREATE INDEX ON reviews USING ivfflat(embed vector_cosine_ops) WITH (lists = 100);
  ```

- Use `sqlalchemy.ext.asyncio` `AsyncSession`.

# 🤖 LLM / RAG Rules

- Retriever: PGVector, `k<=6`, similarity > 0.4.
- Prompt template stored in `data/prompts/answer.md`.
- Output parser enforces keys: `overall`, `pros`, `cons`.
- Aspect YAML: `data/aspects.yaml`; update only via PR.

# 📝 Commit & PR

- Conventional commits.
- All new modules require docstring header with purpose.
- PR requires CI: lint + test + build.

# ⚠️ Anti‑patterns

- No hard‑coded XPath/CSS selectors in multiple files – centralise per extractor.
- Don’t store entire HTML in DB – only structured review JSON.
- Avoid heavy synchronous loops inside FastAPI request handler – offload to asyncio tasks if >5 s.

@README.md
@Dockerfile
@backend/main.py
